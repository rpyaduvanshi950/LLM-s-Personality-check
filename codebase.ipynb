{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNRmARCnye5_"
      },
      "source": [
        "### Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xd5dvrIuJsD",
        "outputId": "c38b93af-c907-4ca4-9485-e8ee4d155677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OpenAI in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from OpenAI) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M_oeHrHygz9"
      },
      "source": [
        "#### MPI TESTING WITHOUT INDUCING THE PERSONALITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1G7wMbJut2o",
        "outputId": "8195293f-1139-4003-e233-68b4da545941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(A). Very Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(A). Very Accurate O\n",
            "(A). Very Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(D). Moderately Inaccurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(C). Neither Accurate Nor Inaccurate O\n",
            "(A). Very Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(A). Very Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(A). Very Accurate O\n",
            "(E). Very Inaccurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(A). Very Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(A). Very Accurate N\n",
            "(A). Very Accurate E\n",
            "(A). Very Accurate O\n",
            "(A). Very Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(A). Very Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(A). Very Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(A). Very Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(C). Neither Accurate Nor Inaccurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(A). Very Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(A). Very Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(A). Very Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(D). Moderately Inaccurate O\n",
            "(E). Very Inaccurate A\n",
            "(A). Very Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(B). Moderately Accurate N\n",
            "(B). Moderately Accurate E\n",
            "(B). Moderately Accurate O\n",
            "(B). Moderately Accurate A\n",
            "(B). Moderately Accurate C\n",
            "(A). Very Accurate N\n",
            "(A). Very Accurate E\n",
            "(A). Very Accurate O\n",
            "(D). Moderately Inaccurate A\n",
            "(B). Moderately Accurate C\n",
            "Results saved to MPI_without_Induction.pickle\n"
          ]
        }
      ],
      "source": [
        "# this code is used to generate the responses for the personality test items using the OpenAI API\n",
        "# The responses are then saved to a pickle file for further analysis.\n",
        "# The code uses the OpenAI API to generate responses to personality test items and stores the results in a pickle file.\n",
        "# The responses are generated in batches to optimize the usage of the API.\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Set OpenAI API key\n",
        "api_key1 = \"api_key\"\n",
        "# Pass the api_key1 variable instead of the string \"api_key1\"\n",
        "client = openai.OpenAI(api_key=api_key1)\n",
        "# File path for personality test items\n",
        "ITEMPATH = \"./mpi_120.csv\"\n",
        "LABEL_TYPE = None  # Placeholder for filtering label type\n",
        "\n",
        "\n",
        "def get_items(filename=ITEMPATH, label_type=LABEL_TYPE):\n",
        "    \"\"\"Load personality test statements from CSV and filter by label type if provided.\"\"\"\n",
        "    data = pd.read_csv(filename)\n",
        "    return data if label_type is None else data[data[\"label_ocean\"] == label_type]\n",
        "\n",
        "# Template for the AI-generated questionnaire\n",
        "QUESTION_TEMPLATE = \"\"\"Question:\n",
        "Given a statement of you: \"You {}.\"\n",
        "Please choose from the following options to identify how accurately this statement describes you.\n",
        "Options:\n",
        "(A). Very Accurate\n",
        "(B). Moderately Accurate\n",
        "(C). Neither Accurate Nor Inaccurate\n",
        "(D). Moderately Inaccurate\n",
        "(E). Very Inaccurate\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "# Load personality statements\n",
        "dataset = get_items(ITEMPATH)\n",
        "\n",
        "# AI Response Generation Parameters\n",
        "BATCH_SIZE = 1\n",
        "TEMPERATURE = 0  # Control randomness of responses\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Process questions in batches\n",
        "for i in range(0, len(dataset), BATCH_SIZE):\n",
        "    batch = dataset.iloc[i : i + BATCH_SIZE]\n",
        "    questions = [QUESTION_TEMPLATE.format(item[\"text\"].lower()) for _, item in batch.iterrows()]\n",
        "\n",
        "    # Get AI-generated responses using OpenAI's new client\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use \"gpt-3.5-turbo\" for a cheaper option\n",
        "        messages=[{\"role\": \"user\", \"content\": question} for question in questions],\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=1000,  # Reduce token usage per response\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    # Store responses with corresponding questions\n",
        "    for j, choice in enumerate(response.choices):\n",
        "        results.append((batch.iloc[j], questions[j], choice.message.content))\n",
        "        print(choice.message.content, batch.iloc[j][\"label_ocean\"])\n",
        "\n",
        "# Save results to a pickle file\n",
        "RESULTS_PATH = \"MPI_without_Induction.pickle\"\n",
        "with open(RESULTS_PATH, \"wb\") as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "print(f\"Results saved to {RESULTS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yFaJuIym-0"
      },
      "source": [
        "### Calculating Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA47DA93wL6Z",
        "outputId": "773b4175-ca48-40a2-831d-0b84c3eff3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to personality_results_without_induction.json\n"
          ]
        }
      ],
      "source": [
        "# We will parse the AI responses and calculate the mean and standard deviation for each trait (OCEAN).\n",
        "#\n",
        "# Instructions:\n",
        "# - Load the stored AI responses using the pickle module.\n",
        "# - Initialize a dictionary to store the count of answer choices.\n",
        "# - Create a dictionary to store scores for each trait (OCEAN).\n",
        "# - Define a function to compute the mean and standard deviation for each trait.\n",
        "# - Process each question response to extract the answer choice and update the counts.\n",
        "# - Assign scores based on the response choice and handle reverse scoring.\n",
        "# - Calculate the mean and standard deviation for each trait.\n",
        "# - Print the results for each trait and the distribution of answer choices.\n",
        "#\n",
        "# Note:\n",
        "# The response choice mapping is as follows:\n",
        "# - A: Very Accurate\n",
        "# - B: Moderately Accurate\n",
        "# - C: Neutral\n",
        "# - D: Moderately Inaccurate\n",
        "# - E: Very Inaccurate  # Reverse scoring\n",
        "#\n",
        "# The response text format is assumed to be consistent with the provided template.\n",
        "# The response text includes the answer choice followed by a non-alphabetic character.\n",
        "# The response choice is extracted using a regular expression pattern.\n",
        "# The key value in the question data determines whether reverse scoring is applied.\n",
        "# The mean and standard deviation are calculated for each trait based on the scores.\n",
        "# The results are printed for each trait and the distribution of answer choices.\n",
        "\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Path to the stored AI responses\n",
        "RESULT_FILE = \"MPI_without_Induction.pickle\"\n",
        "OUTPUT_JSON = \"personality_results_without_induction.json\"\n",
        "\n",
        "# Load stored AI responses\n",
        "with open(RESULT_FILE, 'rb') as f:\n",
        "    all_results = pickle.load(f)\n",
        "\n",
        "# Initialize answer choice count\n",
        "answer_counts = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'UNK': 0}\n",
        "\n",
        "# Dictionary to store scores for each trait (OCEAN)\n",
        "traits = {\n",
        "    \"O\": [],  # Openness\n",
        "    \"C\": [],  # Conscientiousness\n",
        "    \"E\": [],  # Extraversion\n",
        "    \"A\": [],  # Agreeableness\n",
        "    \"N\": []   # Neuroticism\n",
        "}\n",
        "\n",
        "# Score mapping for response choices\n",
        "SCORES = {\n",
        "    \"A\": 5,  # Very Accurate\n",
        "    \"B\": 4,  # Moderately Accurate\n",
        "    \"C\": 3,  # Neutral\n",
        "    \"D\": 2,  # Moderately Inaccurate\n",
        "    \"E\": 1   # Very Inaccurate\n",
        "}\n",
        "\n",
        "def compute_statistics(results):\n",
        "    \"\"\"Calculate mean and standard deviation for each trait.\"\"\"\n",
        "    mean_scores = {trait: np.mean(values) if values else 0 for trait, values in results.items()}\n",
        "    std_dev = {trait: np.std(values) if values else 0 for trait, values in results.items()}\n",
        "    return mean_scores, std_dev\n",
        "\n",
        "# Process each question response\n",
        "for question_data in all_results:\n",
        "    question, response_text, trait_label = question_data  # Unpack stored values\n",
        "\n",
        "    # Extract response choice (A, B, C, D, or E) using regex\n",
        "    match = re.search(r'\\((A|B|C|D|E)\\)', response_text)\n",
        "\n",
        "    if match:\n",
        "        choice = match.group(1)  # Extract letter inside parentheses\n",
        "    else:\n",
        "        choice = 'UNK'  # Unknown response\n",
        "\n",
        "    answer_counts[choice] += 1\n",
        "\n",
        "    # Extract the correct personality trait label\n",
        "    trait_label = question[\"label_ocean\"].strip()  # Ensure it's a valid key (O, C, E, A, N)\n",
        "\n",
        "    if trait_label not in traits:\n",
        "        print(f\"Warning: Unexpected trait label '{trait_label}' found. Skipping entry.\")\n",
        "        continue  # Skip invalid labels\n",
        "\n",
        "    key = question[\"key\"]  # Reverse scoring indicator\n",
        "\n",
        "    # Assign score and handle reverse scoring\n",
        "    score = SCORES.get(choice, 0)\n",
        "    if key == 1:\n",
        "        traits[trait_label].append(score)\n",
        "    else:\n",
        "        traits[trait_label].append(6 - score)  # Reverse scoring\n",
        "\n",
        "# Calculate statistics for each trait\n",
        "mean_scores, std_dev = compute_statistics(traits)\n",
        "\n",
        "# Prepare final results dictionary\n",
        "final_results = {\n",
        "    \"Personality Trait Analysis\": {\n",
        "        trait: {\"Mean\": round(mean_scores[trait], 2), \"Std Dev\": round(std_dev[trait], 2)}\n",
        "        for trait in mean_scores\n",
        "    },\n",
        "    \"Answer Choice Distribution\": answer_counts\n",
        "}\n",
        "\n",
        "# Save results to JSON file\n",
        "with open(OUTPUT_JSON, \"w\") as json_file:\n",
        "    json.dump(final_results, json_file, indent=4)\n",
        "\n",
        "print(f\"Results saved to {OUTPUT_JSON}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W8Gpin5qetz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBieGbftr3z"
      },
      "source": [
        "### Inducing Personality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ147GiGt0GY"
      },
      "source": [
        "#### Personality Prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4Mun5HzBdZ"
      },
      "source": [
        " Generate and Store Model Responses in a Pickle File\n",
        "This script:\n",
        "\n",
        "Loads the dataset.\n",
        "Induces personality for each label_raw.\n",
        "Asks the model the rating question.\n",
        "Stores the raw model responses in a .pkl file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUS3ztbgzIAA",
        "outputId": "f34ef3df-12a4-49ac-c20b-0dc59ba691ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Responses saved to model_responses_after_induction.pkl\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Load dataset\n",
        "FILE_PATH = \"/content/mpi_120.csv\"\n",
        "data = pd.read_csv(FILE_PATH)\n",
        "# Set OpenAI API key\n",
        "api_key1 = \"api_key\"\n",
        "# Pass the api_key1 variable instead of the string \"api_key1\"\n",
        "client = openai.OpenAI(api_key=api_key1)\n",
        "# Personality Induction Prompt\n",
        "# def induce_personality(trait):\n",
        "#     prompt = f\"\"\"You are a person who strongly exhibits the trait of {trait}.\n",
        "#     Describe yourself in a few sentences demonstrating this personality.\"\"\"\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-3.5-turbo\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#         temperature=0.7,\n",
        "#     )\n",
        "#     return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "def induce_personality(trait):\n",
        "    prompt = f\"\"\"You are a person who strongly exhibits the trait of {trait}.\n",
        "    Describe yourself in a few sentences demonstrating this personality.\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    # Access the content using the 'choices' attribute and the 'message' attribute\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# In the main loop, access the answer similarly:\n",
        "answer = response.choices[0].message.content.strip()[0]  # Extract first letter (A-E)\n",
        "\n",
        "# Question Template\n",
        "QUESTION_TEMPLATE = \"\"\"Question:\n",
        "Given a statement of you: \"You {}.\"\n",
        "Please choose from the following options to identify how accurately this statement describes you.\n",
        "Options:\n",
        "(A). Very Accurate\n",
        "(B). Moderately Accurate\n",
        "(C). Neither Accurate Nor Inaccurate\n",
        "(D). Moderately Inaccurate\n",
        "(E). Very Inaccurate\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "# Dictionary to store model responses\n",
        "responses = {}\n",
        "\n",
        "# Iterate through dataset and generate responses\n",
        "for index, row in data.iterrows():\n",
        "    personality_prompt = induce_personality(row[\"label_raw\"])  # Induce Personality\n",
        "    question_prompt = QUESTION_TEMPLATE.format(row[\"text\"])  # Create Question\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": personality_prompt},\n",
        "            {\"role\": \"user\", \"content\": question_prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    # Access the content using the 'choices' attribute and the 'message' attribute\n",
        "    answer = response.choices[0].message.content.strip()[0]  # Extract first letter (A-E)\n",
        "    responses[index] = answer  # Store response in dictionary\n",
        "\n",
        "\n",
        "# Save responses to a pickle file\n",
        "with open(\"model_responses_after_induction.pkl\", \"wb\") as f:\n",
        "    pickle.dump(responses, f)\n",
        "\n",
        "print(\"Responses saved to model_responses_after_induction.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWyvUP-zL0p"
      },
      "source": [
        "Convert Responses to Scores and Compute Statistics\n",
        "This script:\n",
        "\n",
        "Loads the .pkl file and dataset.\n",
        "Converts responses to numerical scores using the key column.\n",
        "Computes mean and standard deviation for each label_ocean.\n",
        "Saves the results in a JSON file.\n",
        "python\n",
        "Copy\n",
        "Edit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccbcn0nTzLko",
        "outputId": "185b4a30-9949-49cd-9ccd-5211ef985b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'A': {'mean': 3.0, 'std': 0.0}, 'C': {'mean': 3.0, 'std': 0.0}, 'E': {'mean': 3.0, 'std': 0.0}, 'N': {'mean': 3.0, 'std': 0.0}, 'O': {'mean': 2.9166666666666665, 'std': 0.4082482904638632}}\n",
            "Statistics saved to personality_scores_after_induction.json\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# Load dataset\n",
        "FILE_PATH = \"/content/mpi_120.csv\"\n",
        "data = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# Load model responses\n",
        "with open(\"model_responses.pkl\", \"rb\") as f:\n",
        "    responses = pickle.load(f)\n",
        "\n",
        "# Define scoring map\n",
        "def convert_to_score(response, key):\n",
        "    score_map = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5}\n",
        "    score = score_map.get(response.strip(), 3)  # Default to 3 if unknown\n",
        "    return score if key == 1 else 6 - score  # Reverse for key = -1\n",
        "\n",
        "# Apply scores to dataset\n",
        "data[\"score\"] = data.index.map(lambda idx: convert_to_score(responses[idx], data.loc[idx, \"key\"]))\n",
        "\n",
        "# Calculate mean & standard deviation per label_ocean\n",
        "stats = data.groupby(\"label_ocean\")[\"score\"].agg([\"mean\", \"std\"]).to_dict(\"index\")\n",
        "print(stats)\n",
        "# Save results to JSON\n",
        "with open(\"personality_scores_after_induction.json\", \"w\") as f:\n",
        "    json.dump(stats, f, indent=4)\n",
        "\n",
        "print(\"Statistics saved to personality_scores_after_induction.json\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
